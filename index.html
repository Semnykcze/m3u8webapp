<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Image Processor - Depth Map & Edge Detection</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/opencv@7.0.0/lib/opencv.min.js"></script>
    <style>
        .loader {
            border: 3px solid #f3f3f3;
            border-top: 3px solid #3498db;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-100 dark:bg-gray-900 transition-colors duration-200">
    <div class="container mx-auto p-4 max-w-7xl">
        <!-- Header -->
        <header class="mb-6 flex justify-between items-center">
            <h1 class="text-3xl font-bold text-gray-800 dark:text-white">
                üñºÔ∏è AI Image Processor
            </h1>
            <button id="themeToggle" class="p-2 rounded-lg bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600">
                <svg class="w-6 h-6 text-gray-800 dark:text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path>
                </svg>
            </button>
        </header>

        <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <!-- Left Panel - Controls -->
            <div class="lg:col-span-1 bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6">
                <h2 class="text-xl font-semibold mb-4 text-gray-800 dark:text-white">Controls</h2>
                
                <!-- Image Upload -->
                <div class="mb-6">
                    <label class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        Upload Image
                    </label>
                    <div id="dropZone" class="border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6 text-center hover:border-blue-500 transition-colors cursor-pointer">
                        <input type="file" id="imageInput" accept="image/*" class="hidden">
                        <svg class="mx-auto h-12 w-12 text-gray-400" stroke="currentColor" fill="none" viewBox="0 0 48 48">
                            <path d="M28 8H12a4 4 0 00-4 4v20m32-12v8m0 0v8a4 4 0 01-4 4H12a4 4 0 01-4-4v-4m32-4l-3.172-3.172a4 4 0 00-5.656 0L28 28M8 32l9.172-9.172a4 4 0 015.656 0L28 28m0 0l4 4m4-24h8m-4-4v8m-12 4h.02" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" />
                        </svg>
                        <p class="mt-2 text-sm text-gray-600 dark:text-gray-400">
                            Click or drag image here
                        </p>
                    </div>
                </div>

                <!-- Processing Mode -->
                <div class="mb-6">
                    <label class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        Processing Mode
                    </label>
                    <select id="modeSelect" class="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-md shadow-sm focus:outline-none focus:ring-blue-500 focus:border-blue-500 dark:bg-gray-700 dark:text-white">
                        <option value="depth">Depth Map</option>
                        <option value="canny">Canny Edge</option>
                        <option value="both">Both (Overlay)</option>
                    </select>
                </div>

                <!-- Canny Parameters -->
                <div id="cannyParams" class="mb-6 hidden">
                    <h3 class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-3">Canny Parameters</h3>
                    <div class="space-y-3">
                        <div>
                            <label class="text-xs text-gray-600 dark:text-gray-400">Low Threshold: <span id="lowThresholdValue">50</span></label>
                            <input type="range" id="lowThreshold" min="0" max="200" value="50" class="w-full">
                        </div>
                        <div>
                            <label class="text-xs text-gray-600 dark:text-gray-400">High Threshold: <span id="highThresholdValue">150</span></label>
                            <input type="range" id="highThreshold" min="0" max="300" value="150" class="w-full">
                        </div>
                    </div>
                </div>

                <!-- Depth Colormap -->
                <div id="depthParams" class="mb-6">
                    <label class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        Depth Colormap
                    </label>
                    <select id="colormapSelect" class="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-md shadow-sm focus:outline-none focus:ring-blue-500 focus:border-blue-500 dark:bg-gray-700 dark:text-white">
                        <option value="grayscale">Grayscale</option>
                        <option value="inferno">Inferno</option>
                        <option value="turbo">Turbo</option>
                        <option value="viridis">Viridis</option>
                    </select>
                </div>

                <!-- Process Button -->
                <button id="processBtn" disabled class="w-full bg-blue-600 text-white py-2 px-4 rounded-md hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors">
                    Process Image
                </button>

                <!-- Status -->
                <div id="status" class="mt-4 text-sm text-gray-600 dark:text-gray-400 text-center"></div>
                
                <!-- Performance -->
                <div id="performance" class="mt-4 p-3 bg-gray-100 dark:bg-gray-700 rounded text-xs text-gray-600 dark:text-gray-400 hidden">
                    <div>Model Load Time: <span id="modelLoadTime">-</span>ms</div>
                    <div>Inference Time: <span id="inferenceTime">-</span>ms</div>
                </div>
            </div>

            <!-- Right Panel - Results -->
            <div class="lg:col-span-2 bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-xl font-semibold text-gray-800 dark:text-white">Results</h2>
                    <div class="flex space-x-2">
                        <button class="tabBtn px-3 py-1 rounded text-sm font-medium bg-blue-600 text-white" data-tab="original">Original</button>
                        <button class="tabBtn px-3 py-1 rounded text-sm font-medium bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300" data-tab="depth">Depth</button>
                        <button class="tabBtn px-3 py-1 rounded text-sm font-medium bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300" data-tab="edges">Edges</button>
                        <button class="tabBtn px-3 py-1 rounded text-sm font-medium bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300" data-tab="overlay">Overlay</button>
                    </div>
                </div>

                <!-- Canvas Container -->
                <div class="relative bg-gray-50 dark:bg-gray-900 rounded-lg p-4 min-h-[400px] flex items-center justify-center">
                    <div id="canvasContainer" class="relative">
                        <canvas id="originalCanvas" class="max-w-full h-auto"></canvas>
                        <canvas id="depthCanvas" class="max-w-full h-auto hidden"></canvas>
                        <canvas id="cannyCanvas" class="max-w-full h-auto hidden"></canvas>
                        <canvas id="overlayCanvas" class="max-w-full h-auto hidden"></canvas>
                        <div id="processingLoader" class="absolute inset-0 bg-white bg-opacity-75 flex items-center justify-center hidden">
                            <div class="loader"></div>
                        </div>
                    </div>
                    <div id="placeholder" class="text-gray-400 dark:text-gray-600">
                        <svg class="w-32 h-32 mx-auto" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="1" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z"></path>
                        </svg>
                        <p class="mt-4 text-center">Upload an image to start</p>
                    </div>
                </div>

                <!-- Download Button -->
                <div class="mt-4 flex justify-end">
                    <button id="downloadBtn" disabled class="bg-green-600 text-white py-2 px-4 rounded-md hover:bg-green-700 disabled:bg-gray-400 disabled:cursor-not-allowed transition-colors">
                        Download Result
                    </button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let currentImage = null;
        let depthModel = null;
        let cvReady = false;
        let currentTab = 'original';

        // Wait for OpenCV.js to be ready
        cv['onRuntimeInitialized'] = () => {
            cvReady = true;
            updateStatus('OpenCV.js loaded');
        };

        // Initialize ONNX Runtime
        ort.env.wasm.numThreads = 1;
        ort.env.wasm.simd = true;

        // UI Elements
        const elements = {
            imageInput: document.getElementById('imageInput'),
            dropZone: document.getElementById('dropZone'),
            processBtn: document.getElementById('processBtn'),
            downloadBtn: document.getElementById('downloadBtn'),
            modeSelect: document.getElementById('modeSelect'),
            colormapSelect: document.getElementById('colormapSelect'),
            lowThreshold: document.getElementById('lowThreshold'),
            highThreshold: document.getElementById('highThreshold'),
            lowThresholdValue: document.getElementById('lowThresholdValue'),
            highThresholdValue: document.getElementById('highThresholdValue'),
            cannyParams: document.getElementById('cannyParams'),
            depthParams: document.getElementById('depthParams'),
            status: document.getElementById('status'),
            performance: document.getElementById('performance'),
            modelLoadTime: document.getElementById('modelLoadTime'),
            inferenceTime: document.getElementById('inferenceTime'),
            placeholder: document.getElementById('placeholder'),
            canvasContainer: document.getElementById('canvasContainer'),
            processingLoader: document.getElementById('processingLoader'),
            themeToggle: document.getElementById('themeToggle'),
            originalCanvas: document.getElementById('originalCanvas'),
            depthCanvas: document.getElementById('depthCanvas'),
            cannyCanvas: document.getElementById('cannyCanvas'),
            overlayCanvas: document.getElementById('overlayCanvas')
        };

        // Theme toggle
        elements.themeToggle.addEventListener('click', () => {
            document.documentElement.classList.toggle('dark');
            localStorage.setItem('theme', document.documentElement.classList.contains('dark') ? 'dark' : 'light');
        });

        // Initialize theme
        if (localStorage.getItem('theme') === 'dark' || (!localStorage.getItem('theme') && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
            document.documentElement.classList.add('dark');
        }

        // Tab switching
        document.querySelectorAll('.tabBtn').forEach(btn => {
            btn.addEventListener('click', () => {
                currentTab = btn.dataset.tab;
                updateTabUI();
                showCanvas(currentTab);
            });
        });

        function updateTabUI() {
            document.querySelectorAll('.tabBtn').forEach(btn => {
                if (btn.dataset.tab === currentTab) {
                    btn.className = 'tabBtn px-3 py-1 rounded text-sm font-medium bg-blue-600 text-white';
                } else {
                    btn.className = 'tabBtn px-3 py-1 rounded text-sm font-medium bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300';
                }
            });
        }

        function showCanvas(tab) {
            const canvases = ['originalCanvas', 'depthCanvas', 'cannyCanvas', 'overlayCanvas'];
            canvases.forEach(id => {
                elements[id].classList.add('hidden');
            });
            
            if (tab === 'original') elements.originalCanvas.classList.remove('hidden');
            else if (tab === 'depth') elements.depthCanvas.classList.remove('hidden');
            else if (tab === 'edges') elements.cannyCanvas.classList.remove('hidden');
            else if (tab === 'overlay') elements.overlayCanvas.classList.remove('hidden');
        }

        // Mode selection
        elements.modeSelect.addEventListener('change', (e) => {
            const mode = e.target.value;
            if (mode === 'canny' || mode === 'both') {
                elements.cannyParams.classList.remove('hidden');
            } else {
                elements.cannyParams.classList.add('hidden');
            }
            
            if (mode === 'depth' || mode === 'both') {
                elements.depthParams.classList.remove('hidden');
            } else {
                elements.depthParams.classList.add('hidden');
            }
        });

        // Threshold sliders
        elements.lowThreshold.addEventListener('input', (e) => {
            elements.lowThresholdValue.textContent = e.target.value;
        });

        elements.highThreshold.addEventListener('input', (e) => {
            elements.highThresholdValue.textContent = e.target.value;
        });

        // File handling
        elements.imageInput.addEventListener('change', handleFileSelect);
        elements.dropZone.addEventListener('click', () => elements.imageInput.click());
        elements.dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            elements.dropZone.classList.add('border-blue-500');
        });
        elements.dropZone.addEventListener('dragleave', () => {
            elements.dropZone.classList.remove('border-blue-500');
        });
        elements.dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            elements.dropZone.classList.remove('border-blue-500');
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                handleFile(files[0]);
            }
        });

        function handleFileSelect(e) {
            const file = e.target.files[0];
            if (file) {
                handleFile(file);
            }
        }

        function handleFile(file) {
            if (!file.type.startsWith('image/')) {
                updateStatus('Please select an image file');
                return;
            }

            const reader = new FileReader();
            reader.onload = (e) => {
                const img = new Image();
                img.onload = () => {
                    currentImage = img;
                    displayImage(img);
                    elements.processBtn.disabled = false;
                    elements.placeholder.classList.add('hidden');
                    elements.canvasContainer.classList.remove('hidden');
                    updateStatus('Image loaded. Ready to process.');
                };
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }

        function displayImage(img) {
            const ctx = elements.originalCanvas.getContext('2d');
            elements.originalCanvas.width = img.width;
            elements.originalCanvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            showCanvas('original');
        }

        function updateStatus(message) {
            elements.status.textContent = message;
        }

        async function loadDepthModel() {
            try {
                updateStatus('Loading depth model...');
                const startTime = performance.now();
                
                // Using a smaller MiDaS model for browser compatibility
                // In production, you would host this model file
                const modelUrl = 'https://huggingface.co/spaces/pytorch/MiDaS/resolve/main/midas_v21_small.onnx';
                
                // For demo purposes, we'll create a mock model
                // In real implementation, you would load the actual ONNX model
                depthModel = {
                    run: async (feeds) => {
                        // Simulate model inference
                        await new Promise(resolve => setTimeout(resolve, 500));
                        const [batch, channels, height, width] = [1, 1, 384, 384];
                        const outputData = new Float32Array(batch * channels * height * width);
                        
                        // Generate mock depth data (in real app, this would be actual model output)
                        for (let i = 0; i < outputData.length; i++) {
                            outputData[i] = Math.random();
                        }
                        
                        return {
                            output: {
                                data: outputData,
                                dims: [batch, channels, height, width]
                            }
                        };
                    }
                };
                
                const loadTime = performance.now() - startTime;
                elements.modelLoadTime.textContent = loadTime.toFixed(2);
                updateStatus('Depth model loaded');
                return true;
            } catch (error) {
                console.error('Error loading model:', error);
                updateStatus('Error loading depth model');
                return false;
            }
        }

        async function preprocessImage(img, targetSize = 384) {
            const canvas = document.createElement('canvas');
            canvas.width = targetSize;
            canvas.height = targetSize;
            const ctx = canvas.getContext('2d');
            
            // Resize image to square
            ctx.drawImage(img, 0, 0, targetSize, targetSize);
            
            // Get image data
            const imageData = ctx.getImageData(0, 0, targetSize, targetSize);
            const data = imageData.data;
            
            // Convert to RGB and normalize
            const float32Data = new Float32Array(3 * targetSize * targetSize);
            for (let i = 0; i < targetSize * targetSize; i++) {
                const idx = i * 4;
                float32Data[i] = data[idx] / 255.0;     // R
                float32Data[i + targetSize * targetSize] = data[idx + 1] / 255.0; // G
                float32Data[i + 2 * targetSize * targetSize] = data[idx + 2] / 255.0; // B
            }
            
            return {
                data: float32Data,
                dims: [1, 3, targetSize, targetSize]
            };
        }

        async function runDepthModel(img) {
            if (!depthModel) {
                const loaded = await loadDepthModel();
                if (!loaded) return null;
            }
            
            updateStatus('Running depth inference...');
            const startTime = performance.now();
            
            // Preprocess image
            const input = await preprocessImage(img);
            
            // Run inference
            const feeds = { input: new ort.Tensor('float32', input.data, input.dims) };
            const results = await depthModel.run(feeds);
            
            const inferenceTime = performance.now() - startTime;
            elements.inferenceTime.textContent = inferenceTime.toFixed(2);
            
            return results.output;
        }

        function applyColormap(depthData, colormap) {
            const width = depthData.dims[3];
            const height = depthData.dims[2];
            const canvas = elements.depthCanvas;
            canvas.width = currentImage.width;
            canvas.height = currentImage.height;
            const ctx = canvas.getContext('2d');
            
            // Create image data
            const imageData = ctx.createImageData(width, height);
            const data = imageData.data;
            const depthArray = depthData.data;
            
            // Normalize depth values
            const min = Math.min(...depthArray);
            const max = Math.max(...depthArray);
            const range = max - min;
            
            for (let i = 0; i < depthArray.length; i++) {
                const normalized = (depthArray[i] - min) / range;
                const color = getColor(normalized, colormap);
                const idx = i * 4;
                data[idx] = color[0];
                data[idx + 1] = color[1];
                data[idx + 2] = color[2];
                data[idx + 3] = 255;
            }
            
            // Put processed image data
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = width;
            tempCanvas.height = height;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.putImageData(imageData, 0, 0);
            
            // Scale to original size
            ctx.drawImage(tempCanvas, 0, 0, canvas.width, canvas.height);
        }

        function getColor(value, colormap) {
            value = Math.max(0, Math.min(1, value));
            
            switch(colormap) {
                case 'grayscale':
                    const gray = Math.floor(value * 255);
                    return [gray, gray, gray];
                
                case 'inferno':
                    // Simplified inferno colormap
                    if (value < 0.25) {
                        return [
                            Math.floor(value * 4 * 87),
                            0,
                            Math.floor(value * 4 * 115)
                        ];
                    } else if (value < 0.5) {
                        const t = (value - 0.25) * 4;
                        return [
                            87 + Math.floor(t * 168),
                            Math.floor(t * 80),
                            115 - Math.floor(t * 51)
                        ];
                    } else if (value < 0.75) {
                        const t = (value - 0.5) * 4;
                        return [
                            255,
                            80 + Math.floor(t * 140),
                            64 - Math.floor(t * 64)
                        ];
                    } else {
                        const t = (value - 0.75) * 4;
                        return [
                            255,
                            220 + Math.floor(t * 35),
                            Math.floor(t * 128)
                        ];
                    }
                
                case 'turbo':
                    // Simplified turbo colormap
                    if (value < 0.2) {
                        return [
                            48 + Math.floor(value * 5 * 40),
                            18 + Math.floor(value * 5 * 60),
                            Math.floor(value * 5 * 240)
                        ];
                    } else if (value < 0.4) {
                        const t = (value - 0.2) * 5;
                        return [
                            88 + Math.floor(t * 100),
                            78 + Math.floor(t * 120),
                            240 - Math.floor(t * 100)
                        ];
                    } else if (value < 0.6) {
                        const t = (value - 0.4) * 5;
                        return [
                            188 + Math.floor(t * 67),
                            198 + Math.floor(t * 57),
                            140 - Math.floor(t * 140)
                        ];
                    } else if (value < 0.8) {
                        const t = (value - 0.6) * 5;
                        return [
                            255,
                            255 - Math.floor(t * 120),
                            Math.floor(t * 80)
                        ];
                    } else {
                        const t = (value - 0.8) * 5;
                        return [
                            255 - Math.floor(t * 100),
                            135 - Math.floor(t * 100),
                            80 - Math.floor(t * 80)
                        ];
                    }
                
                case 'viridis':
                    // Simplified viridis colormap
                    const r = Math.floor(68 + value * (267 - 68));
                    const g = Math.floor(1 + value * (229 - 1));
                    const b = Math.floor(84 + value * (52 - 84));
                    return [r, g, b];
                
                default:
                    return [0, 0, 0];
            }
        }

        function applyCanny(img) {
            if (!cvReady) {
                updateStatus('OpenCV not ready');
                return;
            }
            
            // Create OpenCV mat from image
            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(img, 0, 0);
            
            const imgData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const src = cv.matFromImageData(imgData);
            const dst = new cv.Mat();
            
            // Convert to grayscale
            cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
            
            // Apply Canny edge detection
            const lowThreshold = parseInt(elements.lowThreshold.value);
            const highThreshold = parseInt(elements.highThreshold.value);
            cv.Canny(src, dst, lowThreshold, highThreshold);
            
            // Display result
            cv.imshow(elements.cannyCanvas, dst);
            
            // Clean up
            src.delete();
            dst.delete();
        }

        function createOverlay() {
            const canvas = elements.overlayCanvas;
            canvas.width = currentImage.width;
            canvas.height = currentImage.height;
            const ctx = canvas.getContext('2d');
            
            // Draw depth map with transparency
            ctx.globalAlpha = 0.6;
            ctx.drawImage(elements.depthCanvas, 0, 0);
            
            // Draw edges on top
            ctx.globalAlpha = 0.8;
            ctx.globalCompositeOperation = 'multiply';
            ctx.drawImage(elements.cannyCanvas, 0, 0);
            
            ctx.globalAlpha = 1.0;
            ctx.globalCompositeOperation = 'source-over';
        }

        async function processImage() {
            if (!currentImage) return;
            
            elements.processBtn.disabled = true;
            elements.processingLoader.classList.remove('hidden');
            elements.performance.classList.remove('hidden');
            
            const mode = elements.modeSelect.value;
            
            try {
                if (mode === 'depth' || mode === 'both') {
                    const depthResult = await runDepthModel(currentImage);
                    if (depthResult) {
                        const colormap = elements.colormapSelect.value;
                        applyColormap(depthResult, colormap);
                    }
                }
                
                if (mode === 'canny' || mode === 'both') {
                    applyCanny(currentImage);
                }
                
                if (mode === 'both') {
                    createOverlay();
                    currentTab = 'overlay';
                } else if (mode === 'depth') {
                    currentTab = 'depth';
                } else if (mode === 'canny') {
                    currentTab = 'edges';
                }
                
                updateTabUI();
                showCanvas(currentTab);
                elements.downloadBtn.disabled = false;
                updateStatus('Processing complete');
                
            } catch (error) {
                console.error('Processing error:', error);
                updateStatus('Error during processing');
            } finally {
                elements.processBtn.disabled = false;
                elements.processingLoader.classList.add('hidden');
            }
        }

        function downloadImage() {
            let canvas;
            switch(currentTab) {
                case 'original':
                    canvas = elements.originalCanvas;
                    break;
                case 'depth':
                    canvas = elements.depthCanvas;
                    break;
                case 'edges':
                    canvas = elements.cannyCanvas;
                    break;
                case 'overlay':
                    canvas = elements.overlayCanvas;
                    break;
            }
            
            if (canvas) {
                const link = document.createElement('a');
                link.download = `processed_${currentTab}_${Date.now()}.png`;
                link.href = canvas.toDataURL();
                link.click();
            }
        }

        // Event listeners
        elements.processBtn.addEventListener('click', processImage);
        elements.downloadBtn.addEventListener('click', downloadImage);

        // Initialize
        updateStatus('Ready to process images');
    </script>
</body>
</html>
